{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KHpdDlzYNDI"
      },
      "source": [
        "> Copyright 2024 DeepMind Technologies Limited.\n",
        ">\n",
        "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "> you may not use this file except in compliance with the License.\n",
        "> You may obtain a copy of the License at\n",
        ">\n",
        ">      http://www.apache.org/licenses/LICENSE-2.0\n",
        ">\n",
        "> Unless required by applicable law or agreed to in writing, software\n",
        "> distributed under the License is distributed on an \"AS-IS\" BASIS,\n",
        "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "> See the License for the specific language governing permissions and\n",
        "> limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnMHywhUhlgJ"
      },
      "source": [
        "# GenCast Mini Demo\n",
        "\n",
        "This notebook demonstrates running `GenCast 1p0deg Mini <2019`.\n",
        "\n",
        "`GenCast 1p0deg Mini <2019` is a GenCast model at 1deg resolution, with 13 pressure levels and a 4 times refined icosahedral mesh. It is trained on ERA5 data from 1979 to 2018, and can be causally evaluated on 2019 and later years.\n",
        "\n",
        "While other GenCast models are [available](https://github.com/google-deepmind/graphcast/blob/main/README.md), this model has the smallest memory footprint of those provided and is the only one runnable with the freely provided TPUv2-8 configuration in Colab. You can select this configuration in `Runtime>Change Runtime Type`.\n",
        "\n",
        "**N.B.** The performance of `GenCast 1p0deg Mini <2019` is reasonable but is not representative of the performance of the other GenCast models described in the [README](https://github.com/google-deepmind/graphcast/blob/main/README.md).\n",
        "\n",
        "To run the other models using Google Cloud Compute, refer to [gencast_demo_cloud_vm.ipynb](https://colab.research.google.com/github/deepmind/graphcast/blob/master/gencast_demo_cloud_vm.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMbbXFl4msJw"
      },
      "source": [
        "# Installation and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-gAH79SRwp9G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: importlib_metadata in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (8.7.1)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (from importlib_metadata) (3.23.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# @title Upgrade packages (kernel needs to be restarted after running this cell).\n",
        "\n",
        "%pip install -U importlib_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "233zaiZYqCnc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/deepmind/graphcast/archive/master.zip\n",
            "  Using cached https://github.com/deepmind/graphcast/archive/master.zip\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting cartopy (from graphcast==0.2.0.dev0)\n",
            "  Using cached cartopy-0.25.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
            "Collecting chex (from graphcast==0.2.0.dev0)\n",
            "  Using cached chex-0.1.91-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting colabtools (from graphcast==0.2.0.dev0)\n",
            "  Using cached colabtools-0.0.1-py3-none-any.whl.metadata (511 bytes)\n",
            "Collecting dask (from graphcast==0.2.0.dev0)\n",
            "  Using cached dask-2026.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dinosaur-dycore (from graphcast==0.2.0.dev0)\n",
            "  Using cached dinosaur_dycore-1.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting dm-haiku (from graphcast==0.2.0.dev0)\n",
            "  Using cached dm_haiku-0.0.16-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dm-tree (from graphcast==0.2.0.dev0)\n",
            "  Using cached dm_tree-0.1.9-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
            "Collecting jax (from graphcast==0.2.0.dev0)\n",
            "  Using cached jax-0.9.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jraph (from graphcast==0.2.0.dev0)\n",
            "  Using cached jraph-0.0.6.dev0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting matplotlib (from graphcast==0.2.0.dev0)\n",
            "  Using cached matplotlib-3.10.8-cp312-cp312-win_amd64.whl.metadata (52 kB)\n",
            "Collecting numpy (from graphcast==0.2.0.dev0)\n",
            "  Using cached numpy-2.4.2-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting pandas (from graphcast==0.2.0.dev0)\n",
            "  Using cached pandas-3.0.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
            "Collecting rtree (from graphcast==0.2.0.dev0)\n",
            "  Using cached rtree-1.4.1-py3-none-win_amd64.whl.metadata (2.2 kB)\n",
            "Collecting scipy (from graphcast==0.2.0.dev0)\n",
            "  Using cached scipy-1.17.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Collecting trimesh (from graphcast==0.2.0.dev0)\n",
            "  Using cached trimesh-4.11.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting typing_extensions (from graphcast==0.2.0.dev0)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting xarray (from graphcast==0.2.0.dev0)\n",
            "  Using cached xarray-2026.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting xarray_tensorstore (from graphcast==0.2.0.dev0)\n",
            "  Using cached xarray_tensorstore-0.3.0-py3-none-any.whl.metadata (600 bytes)\n",
            "Collecting shapely>=2.0 (from cartopy->graphcast==0.2.0.dev0)\n",
            "  Using cached shapely-2.1.2-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: packaging>=21 in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (from cartopy->graphcast==0.2.0.dev0) (25.0)\n",
            "Collecting pyshp>=2.3 (from cartopy->graphcast==0.2.0.dev0)\n",
            "  Using cached pyshp-3.0.3-py3-none-any.whl.metadata (65 kB)\n",
            "Collecting pyproj>=3.3.1 (from cartopy->graphcast==0.2.0.dev0)\n",
            "  Using cached pyproj-3.7.2-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->graphcast==0.2.0.dev0)\n",
            "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->graphcast==0.2.0.dev0)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->graphcast==0.2.0.dev0)\n",
            "  Using cached fonttools-4.61.1-cp312-cp312-win_amd64.whl.metadata (116 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->graphcast==0.2.0.dev0)\n",
            "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
            "Collecting pillow>=8 (from matplotlib->graphcast==0.2.0.dev0)\n",
            "  Using cached pillow-12.1.1-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib->graphcast==0.2.0.dev0)\n",
            "  Using cached pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (from matplotlib->graphcast==0.2.0.dev0) (2.9.0.post0)\n",
            "Collecting certifi (from pyproj>=3.3.1->cartopy->graphcast==0.2.0.dev0)\n",
            "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (from python-dateutil>=2.7->matplotlib->graphcast==0.2.0.dev0) (1.17.0)\n",
            "Collecting absl-py>=2.3.1 (from chex->graphcast==0.2.0.dev0)\n",
            "  Using cached absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting jaxlib>=0.7.0 (from chex->graphcast==0.2.0.dev0)\n",
            "  Using cached jaxlib-0.9.0.1-cp312-cp312-win_amd64.whl.metadata (1.4 kB)\n",
            "Collecting toolz>=1.0.0 (from chex->graphcast==0.2.0.dev0)\n",
            "  Using cached toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax->graphcast==0.2.0.dev0)\n",
            "  Using cached ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
            "Collecting opt_einsum (from jax->graphcast==0.2.0.dev0)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting click>=8.1 (from dask->graphcast==0.2.0.dev0)\n",
            "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask->graphcast==0.2.0.dev0)\n",
            "  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.09.0 (from dask->graphcast==0.2.0.dev0)\n",
            "  Using cached fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting partd>=1.4.0 (from dask->graphcast==0.2.0.dev0)\n",
            "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask->graphcast==0.2.0.dev0)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: colorama in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (from click>=8.1->dask->graphcast==0.2.0.dev0) (0.4.6)\n",
            "Collecting locket (from partd>=1.4.0->dask->graphcast==0.2.0.dev0)\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pint (from dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached pint-0.25.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting scikit-learn (from dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached scikit_learn-1.8.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting tree-math (from dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached tree_math-0.2.1-py3-none-any.whl.metadata (477 bytes)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku->graphcast==0.2.0.dev0)\n",
            "  Using cached jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting tabulate>=0.8.9 (from dm-haiku->graphcast==0.2.0.dev0)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting attrs>=18.2.0 (from dm-tree->graphcast==0.2.0.dev0)\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting wrapt>=1.11.2 (from dm-tree->graphcast==0.2.0.dev0)\n",
            "  Using cached wrapt-2.1.1-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
            "Collecting tzdata (from pandas->graphcast==0.2.0.dev0)\n",
            "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting flexcache>=0.3 (from pint->dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached flexcache-0.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting flexparser>=0.4 (from pint->dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached flexparser-0.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: platformdirs>=2.1.0 in c:\\Users\\musti\\miniconda3\\envs\\masters\\Lib\\site-packages (from pint->dinosaur-dycore->graphcast==0.2.0.dev0) (4.5.0)\n",
            "Collecting joblib>=1.3.0 (from scikit-learn->dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting threadpoolctl>=3.2.0 (from scikit-learn->dinosaur-dycore->graphcast==0.2.0.dev0)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting zarr (from xarray_tensorstore->graphcast==0.2.0.dev0)\n",
            "  Using cached zarr-3.1.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tensorstore (from xarray_tensorstore->graphcast==0.2.0.dev0)\n",
            "  Using cached tensorstore-0.1.81-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
            "Collecting donfig>=0.8 (from zarr->xarray_tensorstore->graphcast==0.2.0.dev0)\n",
            "  Using cached donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting google-crc32c>=1.5 (from zarr->xarray_tensorstore->graphcast==0.2.0.dev0)\n",
            "  Using cached google_crc32c-1.8.0-cp312-cp312-win_amd64.whl.metadata (1.8 kB)\n",
            "Collecting numcodecs>=0.14 (from zarr->xarray_tensorstore->graphcast==0.2.0.dev0)\n",
            "  Using cached numcodecs-0.16.5-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
            "Using cached cartopy-0.25.0-cp312-cp312-win_amd64.whl (11.0 MB)\n",
            "Using cached matplotlib-3.10.8-cp312-cp312-win_amd64.whl (8.1 MB)\n",
            "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.61.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
            "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
            "Using cached numpy-2.4.2-cp312-cp312-win_amd64.whl (12.3 MB)\n",
            "Downloading pillow-12.1.1-cp312-cp312-win_amd64.whl (7.0 MB)\n",
            "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.5/7.0 MB 8.5 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 2.9/7.0 MB 10.5 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 5.2/7.0 MB 11.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.0/7.0 MB 10.8 MB/s  0:00:00\n",
            "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Using cached pyproj-3.7.2-cp312-cp312-win_amd64.whl (6.3 MB)\n",
            "Downloading pyshp-3.0.3-py3-none-any.whl (58 kB)\n",
            "Downloading shapely-2.1.2-cp312-cp312-win_amd64.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.7/1.7 MB 9.4 MB/s  0:00:00\n",
            "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading chex-0.1.91-py3-none-any.whl (100 kB)\n",
            "Downloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
            "Downloading jax-0.9.0.1-py3-none-any.whl (3.0 MB)\n",
            "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
            "   ------------------------------- -------- 2.4/3.0 MB 12.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.0/3.0 MB 11.5 MB/s  0:00:00\n",
            "Downloading jaxlib-0.9.0.1-cp312-cp312-win_amd64.whl (60.5 MB)\n",
            "   ---------------------------------------- 0.0/60.5 MB ? eta -:--:--\n",
            "   - -------------------------------------- 2.9/60.5 MB 13.9 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 6.0/60.5 MB 14.2 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 9.2/60.5 MB 14.6 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 12.6/60.5 MB 15.5 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 14.2/60.5 MB 13.9 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 17.3/60.5 MB 14.0 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 20.2/60.5 MB 13.9 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 23.1/60.5 MB 13.9 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 26.5/60.5 MB 14.2 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 29.6/60.5 MB 14.3 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 33.3/60.5 MB 14.6 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 37.0/60.5 MB 14.9 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 40.6/60.5 MB 15.0 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 44.0/60.5 MB 15.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 47.7/60.5 MB 15.3 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 51.1/60.5 MB 15.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 54.3/60.5 MB 15.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 57.7/60.5 MB 15.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  60.3/60.5 MB 15.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 60.5/60.5 MB 15.2 MB/s  0:00:04\n",
            "Downloading ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl (212 kB)\n",
            "Downloading scipy-1.17.1-cp312-cp312-win_amd64.whl (36.5 MB)\n",
            "   ---------------------------------------- 0.0/36.5 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 3.7/36.5 MB 18.2 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 6.8/36.5 MB 16.8 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 10.2/36.5 MB 16.8 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 13.9/36.5 MB 17.1 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 17.6/36.5 MB 17.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 21.2/36.5 MB 17.2 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 24.9/36.5 MB 17.3 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 27.8/36.5 MB 16.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 31.5/36.5 MB 17.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 34.9/36.5 MB 17.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 36.5/36.5 MB 16.4 MB/s  0:00:02\n",
            "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading colabtools-0.0.1-py3-none-any.whl (14 kB)\n",
            "Downloading dask-2026.1.2-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.5/1.5 MB 13.0 MB/s  0:00:00\n",
            "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
            "Downloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
            "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
            "Downloading dinosaur_dycore-1.2.1-py3-none-any.whl (172 kB)\n",
            "Downloading dm_haiku-0.0.16-py3-none-any.whl (374 kB)\n",
            "Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl (102 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading wrapt-2.1.1-cp312-cp312-win_amd64.whl (60 kB)\n",
            "Downloading jraph-0.0.6.dev0-py3-none-any.whl (90 kB)\n",
            "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading pandas-3.0.1-cp312-cp312-win_amd64.whl (9.7 MB)\n",
            "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 2.4/9.7 MB 11.2 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 4.5/9.7 MB 11.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 7.1/9.7 MB 11.5 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 9.2/9.7 MB 11.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.7/9.7 MB 11.2 MB/s  0:00:00\n",
            "Downloading pint-0.25.2-py3-none-any.whl (306 kB)\n",
            "Downloading flexcache-0.3-py3-none-any.whl (13 kB)\n",
            "Downloading flexparser-0.4-py3-none-any.whl (27 kB)\n",
            "Downloading rtree-1.4.1-py3-none-win_amd64.whl (389 kB)\n",
            "Downloading scikit_learn-1.8.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
            "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
            "   ------------- -------------------------- 2.6/8.0 MB 13.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 5.2/8.0 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  7.9/8.0 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.0/8.0 MB 12.4 MB/s  0:00:00\n",
            "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tree_math-0.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading trimesh-4.11.2-py3-none-any.whl (740 kB)\n",
            "   ---------------------------------------- 0.0/740.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 740.3/740.3 kB 10.2 MB/s  0:00:00\n",
            "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Downloading xarray-2026.2.0-py3-none-any.whl (1.4 MB)\n",
            "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.4/1.4 MB 12.2 MB/s  0:00:00\n",
            "Downloading xarray_tensorstore-0.3.0-py3-none-any.whl (10 kB)\n",
            "Downloading tensorstore-0.1.81-cp312-cp312-win_amd64.whl (13.2 MB)\n",
            "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 2.1/13.2 MB 11.8 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 2.1/13.2 MB 11.8 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 2.1/13.2 MB 11.8 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 2.4/13.2 MB 2.7 MB/s eta 0:00:05\n",
            "   -------------- ------------------------- 4.7/13.2 MB 4.5 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 6.3/13.2 MB 5.2 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 8.7/13.2 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.5/13.2 MB 6.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.6/13.2 MB 6.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 13.2/13.2 MB 6.7 MB/s  0:00:01\n",
            "Downloading zarr-3.1.5-py3-none-any.whl (284 kB)\n",
            "Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading google_crc32c-1.8.0-cp312-cp312-win_amd64.whl (34 kB)\n",
            "Downloading numcodecs-0.16.5-cp312-cp312-win_amd64.whl (801 kB)\n",
            "   ---------------------------------------- 0.0/801.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 801.4/801.4 kB 8.7 MB/s  0:00:00\n",
            "Building wheels for collected packages: graphcast\n",
            "  Building wheel for graphcast (pyproject.toml): started\n",
            "  Building wheel for graphcast (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for graphcast: filename=graphcast-0.2.0.dev0-py3-none-any.whl size=136773 sha256=e9ea342a7588f5e10f3309b0766f8371d8413197e8956a2babcef5faa89d34be\n",
            "  Stored in directory: C:\\Users\\musti\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-7n6nydzd\\wheels\\f8\\24\\3a\\f3b9883697c09258da804997b0ec6bf51dd1918f9c61add081\n",
            "Successfully built graphcast\n",
            "Installing collected packages: colabtools, wrapt, tzdata, typing_extensions, toolz, threadpoolctl, tabulate, rtree, pyyaml, pyshp, pyparsing, pillow, opt_einsum, numpy, locket, kiwisolver, joblib, google-crc32c, fsspec, fonttools, cycler, cloudpickle, click, certifi, attrs, absl-py, trimesh, shapely, scipy, pyproj, partd, pandas, numcodecs, ml_dtypes, jmp, flexparser, flexcache, donfig, dm-tree, contourpy, zarr, xarray, tensorstore, scikit-learn, pint, matplotlib, jaxlib, dm-haiku, dask, xarray_tensorstore, jax, cartopy, tree-math, jraph, chex, dinosaur-dycore, graphcast\n",
            "\n",
            "   - --------------------------------------  2/57 [tzdata]\n",
            "   - --------------------------------------  2/57 [tzdata]\n",
            "   - --------------------------------------  2/57 [tzdata]\n",
            "   - --------------------------------------  2/57 [tzdata]\n",
            "   -- -------------------------------------  4/57 [toolz]\n",
            "   ---- -----------------------------------  6/57 [tabulate]\n",
            "   ----- ----------------------------------  8/57 [pyyaml]\n",
            "   ------- -------------------------------- 10/57 [pyparsing]\n",
            "   ------- -------------------------------- 11/57 [pillow]\n",
            "   ------- -------------------------------- 11/57 [pillow]\n",
            "   ------- -------------------------------- 11/57 [pillow]\n",
            "   ------- -------------------------------- 11/57 [pillow]\n",
            "   ------- -------------------------------- 11/57 [pillow]\n",
            "   -------- ------------------------------- 12/57 [opt_einsum]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 13/57 [numpy]\n",
            "   --------- ------------------------------ 14/57 [locket]\n",
            "   ----------- ---------------------------- 16/57 [joblib]\n",
            "   ----------- ---------------------------- 16/57 [joblib]\n",
            "   ----------- ---------------------------- 16/57 [joblib]\n",
            "   ----------- ---------------------------- 16/57 [joblib]\n",
            "   ------------ --------------------------- 18/57 [fsspec]\n",
            "   ------------ --------------------------- 18/57 [fsspec]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   ------------- -------------------------- 19/57 [fonttools]\n",
            "   -------------- ------------------------- 21/57 [cloudpickle]\n",
            "   ---------------- ----------------------- 23/57 [certifi]\n",
            "   ----------------- ---------------------- 25/57 [absl-py]\n",
            "   ----------------- ---------------------- 25/57 [absl-py]\n",
            "   ------------------ --------------------- 26/57 [trimesh]\n",
            "   ------------------ --------------------- 26/57 [trimesh]\n",
            "   ------------------ --------------------- 26/57 [trimesh]\n",
            "   ------------------ --------------------- 26/57 [trimesh]\n",
            "   ------------------ --------------------- 26/57 [trimesh]\n",
            "   ------------------ --------------------- 27/57 [shapely]\n",
            "   ------------------ --------------------- 27/57 [shapely]\n",
            "   ------------------ --------------------- 27/57 [shapely]\n",
            "   ------------------ --------------------- 27/57 [shapely]\n",
            "   ------------------ --------------------- 27/57 [shapely]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   ------------------- -------------------- 28/57 [scipy]\n",
            "   -------------------- ------------------- 29/57 [pyproj]\n",
            "   --------------------- ------------------ 30/57 [partd]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   --------------------- ------------------ 31/57 [pandas]\n",
            "   ---------------------- ----------------- 32/57 [numcodecs]\n",
            "   ---------------------- ----------------- 32/57 [numcodecs]\n",
            "   ----------------------- ---------------- 33/57 [ml_dtypes]\n",
            "   ------------------------- -------------- 36/57 [flexcache]\n",
            "   --------------------------- ------------ 39/57 [contourpy]\n",
            "   ---------------------------- ----------- 40/57 [zarr]\n",
            "   ---------------------------- ----------- 40/57 [zarr]\n",
            "   ---------------------------- ----------- 40/57 [zarr]\n",
            "   ---------------------------- ----------- 40/57 [zarr]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ---------------------------- ----------- 41/57 [xarray]\n",
            "   ----------------------------- ---------- 42/57 [tensorstore]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 43/57 [scikit-learn]\n",
            "   ------------------------------ --------- 44/57 [pint]\n",
            "   ------------------------------ --------- 44/57 [pint]\n",
            "   ------------------------------ --------- 44/57 [pint]\n",
            "   ------------------------------ --------- 44/57 [pint]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   ------------------------------- -------- 45/57 [matplotlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 46/57 [jaxlib]\n",
            "   -------------------------------- ------- 47/57 [dm-haiku]\n",
            "   -------------------------------- ------- 47/57 [dm-haiku]\n",
            "   -------------------------------- ------- 47/57 [dm-haiku]\n",
            "   -------------------------------- ------- 47/57 [dm-haiku]\n",
            "   -------------------------------- ------- 47/57 [dm-haiku]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   --------------------------------- ------ 48/57 [dask]\n",
            "   ---------------------------------- ----- 49/57 [xarray_tensorstore]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 50/57 [jax]\n",
            "   ----------------------------------- ---- 51/57 [cartopy]\n",
            "   ----------------------------------- ---- 51/57 [cartopy]\n",
            "   ----------------------------------- ---- 51/57 [cartopy]\n",
            "   ----------------------------------- ---- 51/57 [cartopy]\n",
            "   ----------------------------------- ---- 51/57 [cartopy]\n",
            "   ------------------------------------ --- 52/57 [tree-math]\n",
            "   ------------------------------------- -- 53/57 [jraph]\n",
            "   ------------------------------------- -- 54/57 [chex]\n",
            "   -------------------------------------- - 55/57 [dinosaur-dycore]\n",
            "   -------------------------------------- - 55/57 [dinosaur-dycore]\n",
            "   ---------------------------------------  56/57 [graphcast]\n",
            "   ---------------------------------------  56/57 [graphcast]\n",
            "   ---------------------------------------- 57/57 [graphcast]\n",
            "\n",
            "Successfully installed absl-py-2.4.0 attrs-25.4.0 cartopy-0.25.0 certifi-2026.1.4 chex-0.1.91 click-8.3.1 cloudpickle-3.1.2 colabtools-0.0.1 contourpy-1.3.3 cycler-0.12.1 dask-2026.1.2 dinosaur-dycore-1.2.1 dm-haiku-0.0.16 dm-tree-0.1.9 donfig-0.8.1.post1 flexcache-0.3 flexparser-0.4 fonttools-4.61.1 fsspec-2026.2.0 google-crc32c-1.8.0 graphcast-0.2.0.dev0 jax-0.9.0.1 jaxlib-0.9.0.1 jmp-0.0.4 joblib-1.5.3 jraph-0.0.6.dev0 kiwisolver-1.4.9 locket-1.0.0 matplotlib-3.10.8 ml_dtypes-0.5.4 numcodecs-0.16.5 numpy-2.4.2 opt_einsum-3.4.0 pandas-3.0.1 partd-1.4.2 pillow-12.1.1 pint-0.25.2 pyparsing-3.3.2 pyproj-3.7.2 pyshp-3.0.3 pyyaml-6.0.3 rtree-1.4.1 scikit-learn-1.8.0 scipy-1.17.1 shapely-2.1.2 tabulate-0.9.0 tensorstore-0.1.81 threadpoolctl-3.6.0 toolz-1.1.0 tree-math-0.2.1 trimesh-4.11.2 typing_extensions-4.15.0 tzdata-2025.3 wrapt-2.1.1 xarray-2026.2.0 xarray_tensorstore-0.3.0 zarr-3.1.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# @title Pip install repo and dependencies\n",
        "\n",
        "%pip install --upgrade https://github.com/deepmind/graphcast/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HH8S9fND3KRB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[optparse.groups]Usage:[/]   \n",
            "  c:\\Users\\musti\\miniconda3\\envs\\masters\\python.exe -m pip install \\[options] <requirement specifier> \\[package-index-options] ...\n",
            "  c:\\Users\\musti\\miniconda3\\envs\\masters\\python.exe -m pip install \\[options] -r <requirements file> \\[package-index-options] ...\n",
            "  c:\\Users\\musti\\miniconda3\\envs\\masters\\python.exe -m pip install \\[options] [-e] <vcs project url> ...\n",
            "  c:\\Users\\musti\\miniconda3\\envs\\masters\\python.exe -m pip install \\[options] [-e] <local project path> ...\n",
            "  c:\\Users\\musti\\miniconda3\\envs\\masters\\python.exe -m pip install \\[options] <archive url/path> ...\n",
            "\n",
            "no such option: -y\n"
          ]
        }
      ],
      "source": [
        "# @title Reconfigure jax if running on TPU.\n",
        "\n",
        "# This is required due to outdated jax and libtpu versions in Colab TPU images.\n",
        "%pip install -y libtpu libtpu-nightly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z_j8ej4Pyg1L"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import dataclasses\n",
        "import datetime\n",
        "import math\n",
        "from google.cloud import storage\n",
        "from typing import Optional\n",
        "import haiku as hk\n",
        "from IPython.display import HTML\n",
        "from IPython import display\n",
        "import ipywidgets as widgets\n",
        "import jax\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import numpy as np\n",
        "import xarray\n",
        "\n",
        "\n",
        "\n",
        "from graphcast import rollout\n",
        "from graphcast import xarray_jax\n",
        "from graphcast import normalization\n",
        "from graphcast import checkpoint\n",
        "from graphcast import data_utils\n",
        "from graphcast import xarray_tree\n",
        "from graphcast import gencast\n",
        "from graphcast import denoiser\n",
        "from graphcast import nan_cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OzYgQ0QN-kn8"
      },
      "outputs": [],
      "source": [
        "# @title Plotting functions\n",
        "\n",
        "def select(\n",
        "    data: xarray.Dataset,\n",
        "    variable: str,\n",
        "    level: Optional[int] = None,\n",
        "    max_steps: Optional[int] = None\n",
        "    ) -> xarray.Dataset:\n",
        "  data = data[variable]\n",
        "  if \"batch\" in data.dims:\n",
        "    data = data.isel(batch=0)\n",
        "  if max_steps is not None and \"time\" in data.sizes and max_steps < data.sizes[\"time\"]:\n",
        "    data = data.isel(time=range(0, max_steps))\n",
        "  if level is not None and \"level\" in data.coords:\n",
        "    data = data.sel(level=level)\n",
        "  return data\n",
        "\n",
        "def scale(\n",
        "    data: xarray.Dataset,\n",
        "    center: Optional[float] = None,\n",
        "    robust: bool = False,\n",
        "    ) -> tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
        "  vmin = np.nanpercentile(data, (2 if robust else 0))\n",
        "  vmax = np.nanpercentile(data, (98 if robust else 100))\n",
        "  if center is not None:\n",
        "    diff = max(vmax - center, center - vmin)\n",
        "    vmin = center - diff\n",
        "    vmax = center + diff\n",
        "  return (data, matplotlib.colors.Normalize(vmin, vmax),\n",
        "          (\"RdBu_r\" if center is not None else \"viridis\"))\n",
        "\n",
        "def plot_data(\n",
        "    data: dict[str, xarray.Dataset],\n",
        "    fig_title: str,\n",
        "    plot_size: float = 5,\n",
        "    robust: bool = False,\n",
        "    cols: int = 4\n",
        "    ) -> tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
        "\n",
        "  first_data = next(iter(data.values()))[0]\n",
        "  max_steps = first_data.sizes.get(\"time\", 1)\n",
        "  assert all(max_steps == d.sizes.get(\"time\", 1) for d, _, _ in data.values())\n",
        "\n",
        "  cols = min(cols, len(data))\n",
        "  rows = math.ceil(len(data) / cols)\n",
        "  figure = plt.figure(figsize=(plot_size * 2 * cols,\n",
        "                               plot_size * rows))\n",
        "  figure.suptitle(fig_title, fontsize=16)\n",
        "  figure.subplots_adjust(wspace=0, hspace=0)\n",
        "  figure.tight_layout()\n",
        "\n",
        "  images = []\n",
        "  for i, (title, (plot_data, norm, cmap)) in enumerate(data.items()):\n",
        "    ax = figure.add_subplot(rows, cols, i+1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(title)\n",
        "    im = ax.imshow(\n",
        "        plot_data.isel(time=0, missing_dims=\"ignore\"), norm=norm,\n",
        "        origin=\"lower\", cmap=cmap)\n",
        "    plt.colorbar(\n",
        "        mappable=im,\n",
        "        ax=ax,\n",
        "        orientation=\"vertical\",\n",
        "        pad=0.02,\n",
        "        aspect=16,\n",
        "        shrink=0.75,\n",
        "        cmap=cmap,\n",
        "        extend=(\"both\" if robust else \"neither\"))\n",
        "    images.append(im)\n",
        "\n",
        "  def update(frame):\n",
        "    if \"time\" in first_data.dims:\n",
        "      td = datetime.timedelta(microseconds=first_data[\"time\"][frame].item() / 1000)\n",
        "      figure.suptitle(f\"{fig_title}, {td}\", fontsize=16)\n",
        "    else:\n",
        "      figure.suptitle(fig_title, fontsize=16)\n",
        "    for im, (plot_data, norm, cmap) in zip(images, data.values()):\n",
        "      im.set_data(plot_data.isel(time=frame, missing_dims=\"ignore\"))\n",
        "\n",
        "  ani = animation.FuncAnimation(\n",
        "      fig=figure, func=update, frames=max_steps, interval=250)\n",
        "  plt.close(figure.number)\n",
        "  return HTML(ani.to_jshtml())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQWk0RRuCjDN"
      },
      "source": [
        "# Load the Data and initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttMHeiGCppjB"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate with Google Cloud Storage\n",
        "\n",
        "# Gives you an authenticated client, in case you want to use a private bucket.\n",
        "gcs_client = storage.Client.create_anonymous_client()\n",
        "gcs_bucket = gcs_client.get_bucket(\"dm_graphcast\")\n",
        "dir_prefix = \"gencast/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty5WSDRjhDBF"
      },
      "source": [
        "## Load the model params\n",
        "\n",
        "Choose one of the two ways of getting model params:\n",
        "- **checkpoint**: You'll get sensible predictions, but are limited to the model architecture that it was trained with, which may not fit on your device.\n",
        "- **random**: You'll get random predictions, but you can change the model architecture and data resolution which may run faster or fit on your device.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMoFXuZXs-xg"
      },
      "outputs": [],
      "source": [
        "# @title Choose the model\n",
        "\n",
        "params_file_options = [\n",
        "    name for blob in gcs_bucket.list_blobs(prefix=(dir_prefix+\"params/\"))\n",
        "    if (name := blob.name.removeprefix(dir_prefix+\"params/\"))]  # Drop empty string.\n",
        "\n",
        "latent_value_options = [int(2**i) for i in range(4, 10)]\n",
        "random_latent_size = widgets.Dropdown(\n",
        "    options=latent_value_options, value=512,description=\"Latent size:\")\n",
        "random_attention_type = widgets.Dropdown(\n",
        "    options=[\"splash_mha\", \"triblockdiag_mha\", \"mha\"], value=\"splash_mha\", description=\"Attention:\")\n",
        "random_mesh_size = widgets.IntSlider(\n",
        "    value=4, min=4, max=6, description=\"Mesh size:\")\n",
        "random_num_heads = widgets.Dropdown(\n",
        "    options=[int(2**i) for i in range(0, 3)], value=4,description=\"Num heads:\")\n",
        "random_attention_k_hop = widgets.Dropdown(\n",
        "    options=[int(2**i) for i in range(2, 5)], value=16,description=\"Attn k hop:\")\n",
        "random_resolution = widgets.Dropdown(\n",
        "    options=[\"1p0\", \"0p25\"], value=\"1p0\", description=\"Resolution:\")\n",
        "\n",
        "def update_latent_options(*args):\n",
        "  def _latent_valid_for_attn(attn, latent, heads):\n",
        "    head_dim, rem = divmod(latent, heads)\n",
        "    if rem != 0:\n",
        "      return False\n",
        "    # Required for splash attn.\n",
        "    if head_dim % 128 != 0:\n",
        "      return attn != \"splash_mha\"\n",
        "    return True\n",
        "  attn = random_attention_type.value\n",
        "  heads = random_num_heads.value\n",
        "  random_latent_size.options = [\n",
        "      latent for latent in latent_value_options\n",
        "      if _latent_valid_for_attn(attn, latent, heads)]\n",
        "\n",
        "# Observe changes to only allow for valid combinations.\n",
        "random_attention_type.observe(update_latent_options, \"value\")\n",
        "random_latent_size.observe(update_latent_options, \"value\")\n",
        "random_num_heads.observe(update_latent_options, \"value\")\n",
        "\n",
        "params_file = widgets.Dropdown(\n",
        "    options=[f for f in params_file_options if \"Mini\" in f],\n",
        "    description=\"Params file:\",\n",
        "    layout={\"width\": \"max-content\"})\n",
        "\n",
        "source_tab = widgets.Tab([\n",
        "    params_file,\n",
        "    widgets.VBox([\n",
        "        random_attention_type,\n",
        "        random_mesh_size,\n",
        "        random_num_heads,\n",
        "        random_latent_size,\n",
        "        random_attention_k_hop,\n",
        "        random_resolution\n",
        "    ]),\n",
        "])\n",
        "source_tab.set_title(0, \"Checkpoint\")\n",
        "source_tab.set_title(1, \"Random\")\n",
        "widgets.VBox([\n",
        "    source_tab,\n",
        "    widgets.Label(value=\"Run the next cell to load the model. Rerunning this cell clears your selection.\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cgfYjE1YhALA"
      },
      "outputs": [],
      "source": [
        "# @title Load the model\n",
        "\n",
        "source = source_tab.get_title(source_tab.selected_index)\n",
        "\n",
        "if source == \"Random\":\n",
        "  params = None  # Filled in below\n",
        "  state = {}\n",
        "  task_config = gencast.TASK\n",
        "  # Use default values.\n",
        "  sampler_config = gencast.SamplerConfig()\n",
        "  noise_config = gencast.NoiseConfig()\n",
        "  noise_encoder_config = denoiser.NoiseEncoderConfig()\n",
        "  # Configure, otherwise use default values.\n",
        "  denoiser_architecture_config = denoiser.DenoiserArchitectureConfig(\n",
        "    sparse_transformer_config = denoiser.SparseTransformerConfig(\n",
        "        attention_k_hop=random_attention_k_hop.value,\n",
        "        attention_type=random_attention_type.value,\n",
        "        d_model=random_latent_size.value,\n",
        "        num_heads=random_num_heads.value\n",
        "        ),\n",
        "    mesh_size=random_mesh_size.value,\n",
        "    latent_size=random_latent_size.value,\n",
        "  )\n",
        "else:\n",
        "  assert source == \"Checkpoint\"\n",
        "  with gcs_bucket.blob(dir_prefix + f\"params/{params_file.value}\").open(\"rb\") as f:\n",
        "    ckpt = checkpoint.load(f, gencast.CheckPoint)\n",
        "  params = ckpt.params\n",
        "  state = {}\n",
        "\n",
        "  task_config = ckpt.task_config\n",
        "  sampler_config = ckpt.sampler_config\n",
        "  noise_config = ckpt.noise_config\n",
        "  noise_encoder_config = ckpt.noise_encoder_config\n",
        "  denoiser_architecture_config = ckpt.denoiser_architecture_config\n",
        "  print(\"Model description:\\n\", ckpt.description, \"\\n\")\n",
        "  print(\"Model license:\\n\", ckpt.license, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2AqgxUgiALy"
      },
      "source": [
        "## Load the example data\n",
        "\n",
        "Example ERA5 datasets are available at 0.25 degree and 1 degree resolution.\n",
        "\n",
        "Example HRES-fc0 datasets are available at 0.25 degree resolution.\n",
        "\n",
        "Some transformations were done from the base datasets:\n",
        "- We accumulated precipitation over 12 hours instead of the default 1 hour.\n",
        "- For HRES-fc0 sea surface temperature, we assigned NaNs to grid cells in which sea surface temperature was NaN in the ERA5 dataset (this remains fixed at all times).\n",
        "\n",
        "The data resolution must match the model that is loaded. Since we are running GenCast Mini, this will be 1 degree.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XGzOww0y_BC"
      },
      "outputs": [],
      "source": [
        "# @title Get and filter the list of available example datasets\n",
        "\n",
        "dataset_file_options = [\n",
        "    name for blob in gcs_bucket.list_blobs(prefix=(dir_prefix + \"dataset/\"))\n",
        "    if (name := blob.name.removeprefix(dir_prefix+\"dataset/\"))]  # Drop empty string.\n",
        "\n",
        "def parse_file_parts(file_name):\n",
        "  return dict(part.split(\"-\", 1) for part in file_name.split(\"_\"))\n",
        "\n",
        "\n",
        "def data_valid_for_model(file_name: str, params_file_name: str):\n",
        "  \"\"\"Check data type and resolution matches.\"\"\"\n",
        "  data_file_parts = parse_file_parts(file_name.removesuffix(\".nc\"))\n",
        "  data_res = data_file_parts[\"res\"].replace(\".\", \"p\")\n",
        "  if source == \"Random\":\n",
        "    return random_resolution.value == data_res\n",
        "  res_matches = data_res in params_file_name.lower()\n",
        "  source_matches = \"Operational\" in params_file_name\n",
        "  if data_file_parts[\"source\"] == \"era5\":\n",
        "    source_matches = not source_matches\n",
        "  return res_matches and source_matches\n",
        "\n",
        "dataset_file = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\", \".join([f\"{k}: {v}\" for k, v in parse_file_parts(option.removesuffix(\".nc\")).items()]), option)\n",
        "        for option in dataset_file_options\n",
        "        if data_valid_for_model(option, params_file.value)\n",
        "    ],\n",
        "    description=\"Dataset file:\",\n",
        "    layout={\"width\": \"max-content\"})\n",
        "widgets.VBox([\n",
        "    dataset_file,\n",
        "    widgets.Label(value=\"Run the next cell to load the dataset. Rerunning this cell clears your selection and refilters the datasets that match your model.\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yz-ekISoJxeZ"
      },
      "outputs": [],
      "source": [
        "# @title Load weather data\n",
        "\n",
        "with gcs_bucket.blob(dir_prefix+f\"dataset/{dataset_file.value}\").open(\"rb\") as f:\n",
        "  example_batch = xarray.load_dataset(f).compute()\n",
        "\n",
        "assert example_batch.dims[\"time\"] >= 3  # 2 for input, >=1 for targets\n",
        "\n",
        "print(\", \".join([f\"{k}: {v}\" for k, v in parse_file_parts(dataset_file.value.removesuffix(\".nc\")).items()]))\n",
        "\n",
        "example_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lXjFvdE6qStr"
      },
      "outputs": [],
      "source": [
        "# @title Choose data to plot\n",
        "\n",
        "plot_example_variable = widgets.Dropdown(\n",
        "    options=example_batch.data_vars.keys(),\n",
        "    value=\"2m_temperature\",\n",
        "    description=\"Variable\")\n",
        "plot_example_level = widgets.Dropdown(\n",
        "    options=example_batch.coords[\"level\"].values,\n",
        "    value=500,\n",
        "    description=\"Level\")\n",
        "plot_example_robust = widgets.Checkbox(value=True, description=\"Robust\")\n",
        "plot_example_max_steps = widgets.IntSlider(\n",
        "    min=1, max=example_batch.dims[\"time\"], value=example_batch.dims[\"time\"],\n",
        "    description=\"Max steps\")\n",
        "\n",
        "widgets.VBox([\n",
        "    plot_example_variable,\n",
        "    plot_example_level,\n",
        "    plot_example_robust,\n",
        "    plot_example_max_steps,\n",
        "    widgets.Label(value=\"Run the next cell to plot the data. Rerunning this cell clears your selection.\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iqzXVpn9_b15"
      },
      "outputs": [],
      "source": [
        "# @title Plot example data\n",
        "\n",
        "plot_size = 7\n",
        "\n",
        "data = {\n",
        "    \" \": scale(select(example_batch, plot_example_variable.value, plot_example_level.value, plot_example_max_steps.value),\n",
        "              robust=plot_example_robust.value),\n",
        "}\n",
        "fig_title = plot_example_variable.value\n",
        "if \"level\" in example_batch[plot_example_variable.value].coords:\n",
        "  fig_title += f\" at {plot_example_level.value} hPa\"\n",
        "\n",
        "plot_data(data, fig_title, plot_size, plot_example_robust.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njD4jsPTPKvJ"
      },
      "outputs": [],
      "source": [
        "# @title Extract training and eval data\n",
        "\n",
        "train_inputs, train_targets, train_forcings = data_utils.extract_inputs_targets_forcings(\n",
        "    example_batch, target_lead_times=slice(\"12h\", \"12h\"), # Only 1AR training.\n",
        "    **dataclasses.asdict(task_config))\n",
        "\n",
        "eval_inputs, eval_targets, eval_forcings = data_utils.extract_inputs_targets_forcings(\n",
        "    example_batch, target_lead_times=slice(\"12h\", f\"{(example_batch.dims['time']-2)*12}h\"), # All but 2 input frames.\n",
        "    **dataclasses.asdict(task_config))\n",
        "\n",
        "print(\"All Examples:  \", example_batch.dims.mapping)\n",
        "print(\"Train Inputs:  \", train_inputs.dims.mapping)\n",
        "print(\"Train Targets: \", train_targets.dims.mapping)\n",
        "print(\"Train Forcings:\", train_forcings.dims.mapping)\n",
        "print(\"Eval Inputs:   \", eval_inputs.dims.mapping)\n",
        "print(\"Eval Targets:  \", eval_targets.dims.mapping)\n",
        "print(\"Eval Forcings: \", eval_forcings.dims.mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DJzie5me2-H"
      },
      "outputs": [],
      "source": [
        "# @title Load normalization data\n",
        "\n",
        "with gcs_bucket.blob(dir_prefix+\"stats/diffs_stddev_by_level.nc\").open(\"rb\") as f:\n",
        "  diffs_stddev_by_level = xarray.load_dataset(f).compute()\n",
        "with gcs_bucket.blob(dir_prefix+\"stats/mean_by_level.nc\").open(\"rb\") as f:\n",
        "  mean_by_level = xarray.load_dataset(f).compute()\n",
        "with gcs_bucket.blob(dir_prefix+\"stats/stddev_by_level.nc\").open(\"rb\") as f:\n",
        "  stddev_by_level = xarray.load_dataset(f).compute()\n",
        "with gcs_bucket.blob(dir_prefix+\"stats/min_by_level.nc\").open(\"rb\") as f:\n",
        "  min_by_level = xarray.load_dataset(f).compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke2zQyuT_sMA"
      },
      "outputs": [],
      "source": [
        "# @title Build jitted functions, and possibly initialize random weights\n",
        "\n",
        "\n",
        "def construct_wrapped_gencast():\n",
        "  \"\"\"Constructs and wraps the GenCast Predictor.\"\"\"\n",
        "  predictor = gencast.GenCast(\n",
        "      sampler_config=sampler_config,\n",
        "      task_config=task_config,\n",
        "      denoiser_architecture_config=denoiser_architecture_config,\n",
        "      noise_config=noise_config,\n",
        "      noise_encoder_config=noise_encoder_config,\n",
        "  )\n",
        "\n",
        "  predictor = normalization.InputsAndResiduals(\n",
        "      predictor,\n",
        "      diffs_stddev_by_level=diffs_stddev_by_level,\n",
        "      mean_by_level=mean_by_level,\n",
        "      stddev_by_level=stddev_by_level,\n",
        "  )\n",
        "\n",
        "  predictor = nan_cleaning.NaNCleaner(\n",
        "      predictor=predictor,\n",
        "      reintroduce_nans=True,\n",
        "      fill_value=min_by_level,\n",
        "      var_to_clean='sea_surface_temperature',\n",
        "  )\n",
        "\n",
        "  return predictor\n",
        "\n",
        "\n",
        "@hk.transform_with_state\n",
        "def run_forward(inputs, targets_template, forcings):\n",
        "  predictor = construct_wrapped_gencast()\n",
        "  return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
        "\n",
        "\n",
        "@hk.transform_with_state\n",
        "def loss_fn(inputs, targets, forcings):\n",
        "  predictor = construct_wrapped_gencast()\n",
        "  loss, diagnostics = predictor.loss(inputs, targets, forcings)\n",
        "  return xarray_tree.map_structure(\n",
        "      lambda x: xarray_jax.unwrap_data(x.mean(), require_jax=True),\n",
        "      (loss, diagnostics),\n",
        "  )\n",
        "\n",
        "\n",
        "def grads_fn(params, state, inputs, targets, forcings):\n",
        "  def _aux(params, state, i, t, f):\n",
        "    (loss, diagnostics), next_state = loss_fn.apply(\n",
        "        params, state, jax.random.PRNGKey(0), i, t, f\n",
        "    )\n",
        "    return loss, (diagnostics, next_state)\n",
        "\n",
        "  (loss, (diagnostics, next_state)), grads = jax.value_and_grad(\n",
        "      _aux, has_aux=True\n",
        "  )(params, state, inputs, targets, forcings)\n",
        "  return loss, diagnostics, next_state, grads\n",
        "\n",
        "\n",
        "if params is None:\n",
        "  init_jitted = jax.jit(loss_fn.init)\n",
        "  params, state = init_jitted(\n",
        "      rng=jax.random.PRNGKey(0),\n",
        "      inputs=train_inputs,\n",
        "      targets=train_targets,\n",
        "      forcings=train_forcings,\n",
        "  )\n",
        "\n",
        "\n",
        "loss_fn_jitted = jax.jit(\n",
        "    lambda rng, i, t, f: loss_fn.apply(params, state, rng, i, t, f)[0]\n",
        ")\n",
        "grads_fn_jitted = jax.jit(grads_fn)\n",
        "run_forward_jitted = jax.jit(\n",
        "    lambda rng, i, t, f: run_forward.apply(params, state, rng, i, t, f)[0]\n",
        ")\n",
        "# We also produce a pmapped version for running in parallel.\n",
        "run_forward_pmap = xarray_jax.pmap(run_forward_jitted, dim=\"sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNutliiCyqA"
      },
      "source": [
        "# Run the model\n",
        "\n",
        "The `chunked_prediction_generator_multiple_runs` iterates over forecast steps, where the 1 step forecast is jitted and samples are pmapped across the chips.\n",
        "This allows us to make efficient use of all devices and parallelise generating an ensemble across them. We then combine the chunks at the end to form our final forecast.\n",
        "\n",
        "Note that the `Autoregressive rollout` cell will take longer than the standard inference time to run when executed for the first time, as this will include code compilation time. This cost does not increase with the number of devices, it is a fixed-cost one time operation whose result can be reused across any number of devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewPPSpxr33hN"
      },
      "outputs": [],
      "source": [
        "# The number of ensemble members should be a multiple of the number of devices.\n",
        "print(f\"Number of local devices {len(jax.local_devices())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7obeY9i9oTtD"
      },
      "outputs": [],
      "source": [
        "# @title Autoregressive rollout (loop in python)\n",
        "\n",
        "print(\"Inputs:  \", eval_inputs.dims.mapping)\n",
        "print(\"Targets: \", eval_targets.dims.mapping)\n",
        "print(\"Forcings:\", eval_forcings.dims.mapping)\n",
        "\n",
        "num_ensemble_members = 8 # @param int\n",
        "rng = jax.random.PRNGKey(0)\n",
        "# We fold-in the ensemble member, this way the first N members should always\n",
        "# match across different runs which use take the same inputs, regardless of\n",
        "# total ensemble size.\n",
        "rngs = np.stack(\n",
        "    [jax.random.fold_in(rng, i) for i in range(num_ensemble_members)], axis=0)\n",
        "\n",
        "chunks = []\n",
        "for chunk in rollout.chunked_prediction_generator_multiple_runs(\n",
        "    # Use pmapped version to parallelise across devices.\n",
        "    predictor_fn=run_forward_pmap,\n",
        "    rngs=rngs,\n",
        "    inputs=eval_inputs,\n",
        "    targets_template=eval_targets * np.nan,\n",
        "    forcings=eval_forcings,\n",
        "    num_steps_per_chunk = 1,\n",
        "    num_samples = num_ensemble_members,\n",
        "    pmap_devices=jax.local_devices()\n",
        "    ):\n",
        "    chunks.append(chunk)\n",
        "predictions = xarray.combine_by_coords(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nIoUfBxBAwqm"
      },
      "outputs": [],
      "source": [
        "# @title Choose predictions to plot\n",
        "\n",
        "plot_pred_variable = widgets.Dropdown(\n",
        "    options=predictions.data_vars.keys(),\n",
        "    value=\"2m_temperature\",\n",
        "    description=\"Variable\")\n",
        "plot_pred_level = widgets.Dropdown(\n",
        "    options=predictions.coords[\"level\"].values,\n",
        "    value=500,\n",
        "    description=\"Level\")\n",
        "plot_pred_robust = widgets.Checkbox(value=True, description=\"Robust\")\n",
        "plot_pred_max_steps = widgets.IntSlider(\n",
        "    min=1,\n",
        "    max=predictions.dims[\"time\"],\n",
        "    value=predictions.dims[\"time\"],\n",
        "    description=\"Max steps\")\n",
        "plot_pred_samples = widgets.IntSlider(\n",
        "    min=1,\n",
        "    max=num_ensemble_members,\n",
        "    value=num_ensemble_members,\n",
        "    description=\"Samples\")\n",
        "\n",
        "widgets.VBox([\n",
        "    plot_pred_variable,\n",
        "    plot_pred_level,\n",
        "    plot_pred_robust,\n",
        "    plot_pred_max_steps,\n",
        "    plot_pred_samples,\n",
        "    widgets.Label(value=\"Run the next cell to plot the predictions. Rerunning this cell clears your selection.\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wn7dccXO5R7C"
      },
      "outputs": [],
      "source": [
        "# @title Plot prediction samples and diffs\n",
        "\n",
        "plot_size = 5\n",
        "plot_max_steps = min(predictions.dims[\"time\"], plot_pred_max_steps.value)\n",
        "\n",
        "fig_title = plot_pred_variable.value\n",
        "if \"level\" in predictions[plot_pred_variable.value].coords:\n",
        "  fig_title += f\" at {plot_pred_level.value} hPa\"\n",
        "\n",
        "for sample_idx in range(plot_pred_samples.value):\n",
        "  data = {\n",
        "      \"Targets\": scale(select(eval_targets, plot_pred_variable.value, plot_pred_level.value, plot_max_steps), robust=plot_pred_robust.value),\n",
        "      \"Predictions\": scale(select(predictions.isel(sample=sample_idx), plot_pred_variable.value, plot_pred_level.value, plot_max_steps), robust=plot_pred_robust.value),\n",
        "      \"Diff\": scale((select(eval_targets, plot_pred_variable.value, plot_pred_level.value, plot_max_steps) -\n",
        "                          select(predictions.isel(sample=sample_idx), plot_pred_variable.value, plot_pred_level.value, plot_max_steps)),\n",
        "                        robust=plot_pred_robust.value, center=0),\n",
        "  }\n",
        "  display.display(plot_data(data, fig_title + f\", Sample {sample_idx}\", plot_size, plot_pred_robust.value))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3m9lW5fN4oL"
      },
      "outputs": [],
      "source": [
        "# @title Plot ensemble mean and CRPS\n",
        "\n",
        "def crps(targets, predictions, bias_corrected = True):\n",
        "  if predictions.sizes.get(\"sample\", 1) < 2:\n",
        "    raise ValueError(\n",
        "        \"predictions must have dim 'sample' with size at least 2.\")\n",
        "  sum_dims = [\"sample\", \"sample2\"]\n",
        "  preds2 = predictions.rename({\"sample\": \"sample2\"})\n",
        "  num_samps = predictions.sizes[\"sample\"]\n",
        "  num_samps2 = (num_samps - 1) if bias_corrected else num_samps\n",
        "  mean_abs_diff = np.abs(\n",
        "      predictions - preds2).sum(\n",
        "          dim=sum_dims, skipna=False) / (num_samps * num_samps2)\n",
        "  mean_abs_err = np.abs(targets - predictions).sum(dim=\"sample\", skipna=False) / num_samps\n",
        "  return mean_abs_err - 0.5 * mean_abs_diff\n",
        "\n",
        "\n",
        "plot_size = 5\n",
        "plot_max_steps = min(predictions.dims[\"time\"], plot_pred_max_steps.value)\n",
        "\n",
        "fig_title = plot_pred_variable.value\n",
        "if \"level\" in predictions[plot_pred_variable.value].coords:\n",
        "  fig_title += f\" at {plot_pred_level.value} hPa\"\n",
        "\n",
        "data = {\n",
        "    \"Targets\": scale(select(eval_targets, plot_pred_variable.value, plot_pred_level.value, plot_max_steps), robust=plot_pred_robust.value),\n",
        "    \"Ensemble Mean\": scale(select(predictions.mean(dim=[\"sample\"]), plot_pred_variable.value, plot_pred_level.value, plot_max_steps), robust=plot_pred_robust.value),\n",
        "    \"Ensemble CRPS\": scale(crps((select(eval_targets, plot_pred_variable.value, plot_pred_level.value, plot_max_steps)),\n",
        "                        select(predictions, plot_pred_variable.value, plot_pred_level.value, plot_max_steps)),\n",
        "                      robust=plot_pred_robust.value, center=0),\n",
        "}\n",
        "display.display(plot_data(data, fig_title, plot_size, plot_pred_robust.value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ZhRFBPD0kq"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "The following operations requires larger amounts of memory than running inference.\n",
        "\n",
        "The first time executing the cell takes more time, as it includes the time to jit the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv-u3dAP7IRZ"
      },
      "outputs": [],
      "source": [
        "# @title Loss computation\n",
        "loss, diagnostics = loss_fn_jitted(\n",
        "    jax.random.PRNGKey(0),\n",
        "    train_inputs,\n",
        "    train_targets,\n",
        "    train_forcings)\n",
        "print(\"Loss:\", float(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBNFq1IGZNLz"
      },
      "outputs": [],
      "source": [
        "# @title Gradient computation\n",
        "loss, diagnostics, next_state, grads = grads_fn_jitted(\n",
        "    params=params,\n",
        "    state=state,\n",
        "    inputs=train_inputs,\n",
        "    targets=train_targets,\n",
        "    forcings=train_forcings)\n",
        "mean_grad = np.mean(jax.tree_util.tree_flatten(jax.tree_util.tree_map(lambda x: np.abs(x).mean(), grads))[0])\n",
        "print(f\"Loss: {loss:.4f}, Mean |grad|: {mean_grad:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GenCast Mini Demo",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "masters",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
